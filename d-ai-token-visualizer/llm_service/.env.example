# Local LLM Configuration
# Copy this file to .env and fill in your actual values

# Hugging Face Authentication
# 1. Go to: https://huggingface.co/settings/tokens
# 2. Create a new token with "Read" permissions
# 3. Accept Gemma 2 license at: https://huggingface.co/google/gemma-2-2b
HUGGINGFACE_TOKEN=your_hf_token_here

# Model Configuration
LOCAL_MODEL_NAME=google/gemma-2-2b
DEVICE=auto
# Quantization options: None (no quantization), Q4 (4-bit), Q8 (8-bit)
QUANTIZATION=Q4

# Service Configuration
LLM_SERVICE_HOST=0.0.0.0
LLM_SERVICE_PORT=8001

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG demo level 2\n",
    "In more advanced demonstration we will add hierarchical and graph approaches by extracting metadata, finding and storing relationships between documents and adding summarizations for aggregate questions.\n",
    "\n",
    "## Step 2 - Storing graph in PostgreSQL using AGE extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "\n",
    "original_dir = os.getcwd()\n",
    "try:\n",
    "    # Jump into the terraform directory\n",
    "    os.chdir('terraform')\n",
    "\n",
    "    # Get the database connection string\n",
    "    PGHOST = subprocess.run(['terraform', 'output', '-raw', 'PGHOST'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    PGDATABASE = subprocess.run(['terraform', 'output', '-raw', 'PGDATABASE'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    PGUSER = subprocess.run(['terraform', 'output', '-raw', 'PGUSER'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    PGPASSWORD = subprocess.run(['terraform', 'output', '-raw', 'PGPASSWORD'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    db_uri = f\"postgresql://{PGUSER}:{PGPASSWORD}@{PGHOST}/{PGDATABASE}?sslmode=require\"\n",
    "\n",
    "    # Get the embedding model endpoint and key\n",
    "    model_configurations = subprocess.run(['terraform', 'output', '-raw', 'model_configurations'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    model_config = json.loads(model_configurations)\n",
    "    embedding_model = model_config[\"models\"][\"text-embedding-3-large\"]\n",
    "    EMBEDDINGS_ENDPOINT = embedding_model[\"endpoint\"]\n",
    "    EMBEDDINGS_KEY = embedding_model[\"key\"]\n",
    "    gpt_4o_mini_model = model_config[\"models\"][\"gpt-4o-mini\"]\n",
    "    GPT_4O_MINI_ENDPOINT = gpt_4o_mini_model[\"endpoint\"]\n",
    "    GPT_4O_MINI_KEY = gpt_4o_mini_model[\"key\"]\n",
    "    gpt_4o_model = model_config[\"models\"][\"gpt-4o\"]\n",
    "    GPT_4O_ENDPOINT = gpt_4o_model[\"endpoint\"]\n",
    "    GPT_4O_KEY = gpt_4o_model[\"key\"]\n",
    "\n",
    "    print(f\"Using {db_uri} as the database connection string\")\n",
    "    print(f\"Using {EMBEDDINGS_ENDPOINT} as the embedding model endpoint\")\n",
    "    print(f\"Using {GPT_4O_MINI_ENDPOINT} as the gpt-4o-mini model endpoint\")\n",
    "    print(f\"Using {GPT_4O_ENDPOINT} as the gpt-4o model endpoint\")\n",
    "\n",
    "finally:\n",
    "    os.chdir(original_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create clients for PostgreSQL and OpenAI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from openai import AzureOpenAI \n",
    "import pandas as pd\n",
    "import age\n",
    "\n",
    "conn = psycopg2.connect(db_uri)\n",
    "\n",
    "gpt_4o_client = AzureOpenAI(  \n",
    "    azure_endpoint=GPT_4O_ENDPOINT,  \n",
    "    api_key=GPT_4O_KEY,  \n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "gpt_4o_mini_client = AzureOpenAI(\n",
    "    azure_endpoint=GPT_4O_MINI_ENDPOINT,  \n",
    "    api_key=GPT_4O_MINI_KEY,  \n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and configure extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>extname</th>\n",
       "      <th>extowner</th>\n",
       "      <th>extnamespace</th>\n",
       "      <th>extrelocatable</th>\n",
       "      <th>extversion</th>\n",
       "      <th>extconfig</th>\n",
       "      <th>extcondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14258</td>\n",
       "      <td>plpgsql</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24762</td>\n",
       "      <td>vector</td>\n",
       "      <td>10</td>\n",
       "      <td>2200</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25082</td>\n",
       "      <td>pg_diskann</td>\n",
       "      <td>10</td>\n",
       "      <td>2200</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25102</td>\n",
       "      <td>azure_ai</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25184</td>\n",
       "      <td>age</td>\n",
       "      <td>10</td>\n",
       "      <td>25183</td>\n",
       "      <td>False</td>\n",
       "      <td>1.5.0</td>\n",
       "      <td>[25185, 25197]</td>\n",
       "      <td>[, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     oid     extname  extowner  extnamespace  extrelocatable extversion  \\\n",
       "0  14258     plpgsql        10            11           False        1.0   \n",
       "1  24762      vector        10          2200            True      0.7.0   \n",
       "2  25082  pg_diskann        10          2200           False      0.4.0   \n",
       "3  25102    azure_ai        10            11           False      1.1.0   \n",
       "4  25184         age        10         25183           False      1.5.0   \n",
       "\n",
       "        extconfig extcondition  \n",
       "0            None         None  \n",
       "1            None         None  \n",
       "2            None         None  \n",
       "3            None         None  \n",
       "4  [25185, 25197]         [, ]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "SELECT * FROM pg_extension;\n",
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(command)\n",
    "    result = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "\n",
    "pd.DataFrame(result, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"\"\"\n",
    "CREATE EXTENSION IF NOT EXISTS vector;\n",
    "CREATE EXTENSION IF NOT EXISTS pg_diskann CASCADE;\n",
    "CREATE EXTENSION IF NOT EXISTS azure_ai;\n",
    "CREATE EXTENSION IF NOT EXISTS age CASCADE;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(command)\n",
    "        conn.commit()\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"\"\"\n",
    "select azure_ai.set_setting('azure_openai.endpoint','{EMBEDDINGS_ENDPOINT}'); \n",
    "select azure_ai.set_setting('azure_openai.subscription_key', '{EMBEDDINGS_KEY}'); \n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(command)\n",
    "        conn.commit()\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable AGE for this connection\n",
    "\n",
    "command = \"\"\"\n",
    "SET search_path = ag_catalog, \"$user\", public;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(command)\n",
    "        conn.commit()\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3458 movies\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_json(\"data/test.json\", orient=\"records\")\n",
    "print(f\"Loaded {len(movies_df)} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: graph \"movies_graph\" already exists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create movies graph\n",
    "\n",
    "command = \"\"\"\n",
    "SELECT create_graph('movies_graph');\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(command)\n",
    "        conn.commit()\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in movies_df.iterrows():\n",
    "    movie_id = str(row['id'])\n",
    "    movie_title = str(row['title']).replace(\"'\", \"\\\\'\") if row['title'] is not None else \"\"\n",
    "    movie_overview = str(row['overview']).replace(\"'\", \"\\\\'\") if row['overview'] is not None else \"\"\n",
    "\n",
    "    command = f\"\"\"\n",
    "    SELECT * FROM cypher('movies_graph', $$\n",
    "        MERGE (m:Movie {{id: '{movie_id}'}})\n",
    "        SET m.title = '{movie_title}',\n",
    "            m.overview = '{movie_overview}'\n",
    "        RETURN m\n",
    "    $$) as (m agtype);\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(command)\n",
    "            conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"Inserted {idx+1}/{len(movies_df)} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert traits (metadata, communities) into graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed genres for 1/3458 movies\n",
      "Processed genres for 201/3458 movies\n",
      "Processed genres for 401/3458 movies\n",
      "Processed genres for 601/3458 movies\n",
      "Processed genres for 801/3458 movies\n",
      "Processed genres for 1001/3458 movies\n",
      "Processed genres for 1201/3458 movies\n",
      "Processed genres for 1401/3458 movies\n",
      "Processed genres for 1601/3458 movies\n",
      "Processed genres for 1801/3458 movies\n",
      "Processed genres for 2001/3458 movies\n",
      "Processed genres for 2201/3458 movies\n",
      "Processed genres for 2401/3458 movies\n",
      "Processed genres for 2601/3458 movies\n",
      "Processed genres for 2801/3458 movies\n",
      "Processed genres for 3001/3458 movies\n",
      "Processed genres for 3201/3458 movies\n",
      "Processed genres for 3401/3458 movies\n"
     ]
    }
   ],
   "source": [
    "traits = {\n",
    "    \"characters\": (\"Character\", \"FEATURES_CHARACTER\"),\n",
    "    \"themes\": (\"Theme\", \"INCLUDES_THEME\"),\n",
    "    \"setting\": (\"Setting\", \"SET_IN\"),\n",
    "    \"series\": (\"Series\", \"PART_OF_SERIES\"),\n",
    "}\n",
    "\n",
    "for idx, row in movies_df.iterrows():\n",
    "    movie_id = str(row['id'])\n",
    "    for trait_attr, (node_label, rel_type) in traits.items():\n",
    "        trait_values = row.get(trait_attr)\n",
    "        if not trait_values:\n",
    "            continue\n",
    "        for trait in trait_values:\n",
    "            safe_trait = str(trait).replace(\"'\", \"\\\\'\")\n",
    "            cypher_query = f\"\"\"\n",
    "            SELECT * FROM cypher('movies_graph', $$\n",
    "                MERGE (g:{node_label} {{name: '{safe_trait}'}})\n",
    "                WITH g\n",
    "                MATCH (m:Movie {{id: '{movie_id}'}})\n",
    "                MERGE (m)-[:{rel_type}]->(g)\n",
    "                RETURN m, g$$) as (m agtype, g agtype);\n",
    "            \"\"\"\n",
    "            try:\n",
    "                with conn.cursor() as cursor:\n",
    "                    cursor.execute(cypher_query)\n",
    "                    conn.commit()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing movie id {movie_id} for {trait_attr} '{trait}': {e}\")\n",
    "                conn.rollback()\n",
    "\n",
    "    if idx % 200 == 0:\n",
    "        print(f\"Processed genres for {idx+1}/{len(movies_df)} movies\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
